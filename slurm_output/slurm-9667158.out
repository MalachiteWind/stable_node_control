Using Python version:
Python 3.11.13
Using Conda environment: atscale
Starting experiment with decay_val=0.8
Epoch 0: Loss: 0.0025236992. time = 363.5065283775s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 1: Loss: 0.0003007931. time = 332.7935495377s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 2: Loss: 0.0002811835. time = 258.0217893124s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 3: Loss: 0.0002906982. time = 248.3870549202s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 4: Loss: 0.0002914627. time = 248.3962397575s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 5: Loss: 0.0002915125. time = 253.3478868008s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 10: Loss: 0.0002915173. time = 245.9149017334s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 20: Loss: 0.0002915173. time = 246.2411022186s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 30: Loss: 0.0002915173. time = 246.0210206509s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 40: Loss: 0.0002915173. time = 246.2049548626s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 50: Loss: 0.0002915173. time = 246.1153073311s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 60: Loss: 0.0002915173. time = 246.1582772732s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 70: Loss: 0.0002915173. time = 246.4147706032s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 80: Loss: 0.0002915173. time = 246.5832204819s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 90: Loss: 0.0002915173. time = 246.5795302391s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 100: Loss: 0.0002915173. time = 246.5063982010s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 110: Loss: 0.0002915173. time = 246.6721024513s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 120: Loss: 0.0002915173. time = 246.6409943104s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 130: Loss: 0.0002915173. time = 246.6449310780s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 140: Loss: 0.0002915173. time = 246.6759526730s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 150: Loss: 0.0002915173. time = 246.4657180309s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 160: Loss: 0.0002915173. time = 246.4452142715s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 170: Loss: 0.0002915173. time = 246.4073619843s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 180: Loss: 0.0002915173. time = 246.9830350876s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 190: Loss: 0.0002915173. time = 246.9578635693s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 200: Loss: 0.0002915173. time = 247.0259363651s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 210: Loss: 0.0002915173. time = 247.0516774654s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 220: Loss: 0.0002915173. time = 247.1877808571s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 230: Loss: 0.0002915173. time = 247.0549407005s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 240: Loss: 0.0002915173. time = 247.0763366222s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 250: Loss: 0.0002915173. time = 247.2892708778s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 260: Loss: 0.0002915173. time = 247.1231532097s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 270: Loss: 0.0002915173. time = 247.2417085171s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 280: Loss: 0.0002915173. time = 247.2983047962s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 290: Loss: 0.0002915173. time = 247.3183386326s. lr = 0.0100000000. alpha = 0.8000000000
Epoch 300: Loss: 0.0002915173. time = 247.4047827721s. lr = 0.0100000000. alpha = 0.8000000000
Patience exceeded: 300. Early stoppage executed.
Training complete âœ…
Model/logs saved in: results/multi_k_runs/decay_08
Finished experiment with decay_val=0.8
All experiments finished.
